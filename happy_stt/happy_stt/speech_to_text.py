import rclpy
from rclpy.node import Node
from happy_voice_msgs.srv import SpeechToText

import torch
from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline
import sounddevice as sd
import numpy as np
import time
from collections import deque
import sys

sys.path.append("/workspace/models/silero-vad")
from silero_vad import SileroVAD

class SpeechToTextNode(Node):
    def __init__(self):
        super().__init__('speech_to_text_node')
        self.get_logger().info('ğŸ™ï¸ STTãƒãƒ¼ãƒ‰ã‚’èµ·å‹•ä¸­...')

        # ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹ã¨ãƒ‡ãƒ¼ã‚¿å‹
        device = "cuda:0" if torch.cuda.is_available() else "cpu"
        dtype = torch.float16 if torch.cuda.is_available() else torch.float32

        # Whisper ãƒ¢ãƒ‡ãƒ«ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ï¼‰
        model_dir = "/workspace/models/distil-whisper"

        self.model = AutoModelForSpeechSeq2Seq.from_pretrained(
            model_dir,
            torch_dtype=dtype,
            low_cpu_mem_usage=True,
            use_safetensors=True
        ).to(device)

        self.processor = AutoProcessor.from_pretrained(model_dir)
        self.pipe = pipeline(
            "automatic-speech-recognition",
            model=self.model,
            tokenizer=self.processor.tokenizer,
            feature_extractor=self.processor.feature_extractor,
            max_new_tokens=128,
            torch_dtype=dtype,
            device=device,
        )

        # ğŸ” ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã§ã¯ãªããƒ­ãƒ¼ã‚«ãƒ«æ§‹é€ ã‹ã‚‰èª­ã¿è¾¼ã‚€
        self.vad_model = SileroVAD()
        self.vad_model.load_state_dict(torch.load("/workspace/models/silero_vad.pt"))
        self.vad_model.eval()

        self.get_logger().info("âœ… Silero VAD ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿ã¾ã—ãŸ")

        # ROS2 ã‚µãƒ¼ãƒ“ã‚¹ã®ä½œæˆ
        self.srv = self.create_service(SpeechToText, 'speech_to_text', self.speech_callback)

    def speech_callback(self, request, response):
        self.get_logger().info('ğŸ›ï¸ ã‚µãƒ¼ãƒ“ã‚¹ãŒå‘¼ã³å‡ºã•ã‚Œã¾ã—ãŸ')
        self.get_logger().info('ğŸ§ éŒ²éŸ³é–‹å§‹ã—ã¾ã™ï¼ˆãƒ”ãƒƒï¼‰')
        self.beep()
        audio = self.record_until_silence()
        self.beep()
        result = self.pipe(audio)
        response.text = result['text']
        self.get_logger().info(f"âœ… èªè­˜çµæœ: {response.text}")
        return response

    def beep(self, duration=0.15, freq=880, samplerate=44100):
        t = np.linspace(0, duration, int(samplerate * duration), False)
        tone = 0.5 * np.sin(freq * 2 * np.pi * t)
        sd.play(tone, samplerate=samplerate)
        sd.wait()

    def record_until_silence(self, max_duration=10, silence_duration=1.5, device_index=None):
        samplerate = 16000
        frame_size = 512  # Silero VAD ãŒè¦æ±‚ã™ã‚‹å›ºå®šé•·
        frame_duration = frame_size / samplerate  # ç´„32ms

        buffer = []
        silence_buffer = deque(maxlen=int(silence_duration / frame_duration))
        start_time = time.time()

        with sd.InputStream(samplerate=samplerate, channels=1, dtype='float32', blocksize=frame_size, device=device_index) as stream:
            self.get_logger().info("ğŸ—£ï¸ ç™ºè©±æ¤œçŸ¥ã‚’å¾…æ©Ÿä¸­...")
            while True:
                chunk, _ = stream.read(frame_size)
                chunk = np.squeeze(chunk)

                audio_tensor = torch.from_numpy(chunk).unsqueeze(0)

                with torch.no_grad():
                    prob = self.vad_model(audio_tensor, sr=samplerate).item()

                if prob > 0.5:
                    buffer.append(chunk)
                    silence_buffer.clear()
                elif buffer:
                    silence_buffer.append(chunk)
                    if len(silence_buffer) == silence_buffer.maxlen:
                        buffer.extend(silence_buffer)
                        break

                if time.time() - start_time > max_duration:
                    self.get_logger().warn("âš ï¸ æœ€å¤§éŒ²éŸ³æ™‚é–“ã«é”ã—ã¾ã—ãŸ")
                    break

        if buffer:
            return np.concatenate(buffer)
        else:
            self.get_logger().warn("âš ï¸ éŸ³å£°ãŒæ¤œå‡ºã•ã‚Œãšã€éŒ²éŸ³ãŒç©ºã§ã—ãŸ")
            return np.zeros(1, dtype=np.float32)


def main(args=None):
    rclpy.init(args=args)
    node = SpeechToTextNode()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    node.destroy_node()
    rclpy.shutdown()
